---
title: "Bachelor Thesis"
author: "Stefan Weiss"
date: "2023-07-20"
output:
  pdf_document:
    toc: true
    number_sections: true
documentclass: report
---

\clearpage



# Introduction
Currently, some research interest has shifted from studying
stationary signals to exploring the dynamics of time dependent signals. A traditional method for identifying a signals’
spectral properties is the Fourier transform. Applying the
Fourier transform is based on the assumption that the signal is
stationary and ergodic [37]. However, this allows estimating
the signal characteristics only in average but not the dynamics.
One approach for analyzing non-stationary signals is to use a
windowed Fourier transform. While using this method a nonstationary signal is pre-divided into segments (windows) where
the signal is considered as stationary. Moreover, the Heisenberg uncertainty principle for Fourier analysis [36] makes it
impossible to determine time and frequency simultaneously.
We can only state that the coordinate resolution of a windowed
transform is determined by the width of the window function
and is inversely proportional to the frequency resolution [35].
For the Fourier and the windowed Fourier transforms these
restrictions are fundamental [36].

\clearpage

## Fourier Transformation

Fast Fourier Transform (FFT) for signal processing can be
particularly problematic when the signal consists of randomly
occurring transients superimposed on a more continuous signal
[37]. Unfortunately, many signals, for example most of the signals resulting from biological processes are non-stationary and
non-ergodic. Applying the classical spectral analysis and the
Fourier transformation in the window to study the dynamics
of the signals negatively affects the results. If the task is to
investigate the reaction in biological systems, it is necessary
to extract the information about the time and the frequency
of some events in the signal. 
\clearpage

\clearpage

## Wavelet Transform

In this context wavelet analysis
turned up as a solution to the problem of pinpointing local
events. Morle and Grossman (1982-1984) [35] proposed to
use wavelet transforms of nonstationary signals. Here the nonstationary signal is decomposed into certain basic functions
(other than harmonic), which are obtained from a prototype
function by compression and shift. The prototype function
is called the mother (basic) wavelet [35]. Usually one of
following functions is used as mother wavelet: Mexican Hat,
Daubechies Wavelet, Haar Wavelet, Morlet Wavelet and others
[35], [38]. Among the most effective wavelets we find the
Hermitian wavelets - a family of continuous wavelets, which
are defined as the derivative of a Gaussian distribution [39].
These wavelets are very suitable for the analysis of signals
containing some peaks, for example for the detection of singularities generated by localized defects in a mechanical system
[40], [41], [42], [43]. But Hermitian functions are functions
of a continuous argument which leads to difficulties in their
application when implementing appropriate algorithms.

\clearpage

\clearpage

### Kratwchouk Functionals

pplication when implementing appropriate algorithms.
In this context we propose to use Krawtchouk functions [2],
[3] as mother wavelets. Krawtchouk functions are the discrete
analogue of Hermitian functions by using a simple idea: Since
polynomials are completely determined by their values at a
sufficiently large number of different points, it is possible
to define orthogonality (and also orthonormality) relations on
certain polynomials by using only a discrete finite set of points.
Their application to automated spectral analysis of arbitrary
signals is free from the drawbacks which appear while using
polynomials as functions of a continuous argument. Thus, our
proposal to use the discrete Krawchouk functions as wavelets
in signal processing is an advantage over classical approaches,but does not yet solve all problems. Also wavelets fit into the
principle of uncertainty because a basic wavelet is defined on
a short time interval which corresponds to high frequency.
When the wavelet is stretched this time interval gets longer
and the frequency decreases [35], [34], [36]. This is also true
for Hermite wavelets [36], [44], [46].
Neither classical Fourier analysis nor wavelet analysis can
give a satisfactory answer to the questions ”what?” and
”when?”. However, our visual system can solve the problem of
finding the answer to the questions ”what?” and ”where?” in an
excellent way, which for one-dimensional signals is equivalent
to the question ”when?”. Therefore, we suggest to supplement
the wavelet analysis by a new method which is based on a
model of the visual system, a method to extract the features
of the signal which are invariant to shifts.
\clearpage

\clearpage

\clearpage

### Convolution Theorem

\clearpage

\clearpage

# Time Series Analysis

\clearpage

## Modelling EEG and ECG

\clearpage

\clearpage


## Neural Network Model

The problem of extracting a complete system of invariant
features of a signal arises in signal processing (including
images) as well as in automatic pattern recognition or automatic classification and diagnostics. It is necessary to separate
the information about the characteristics of the signal from
the information about the transformations that this signal has
undergone. These transformations (e.g. shift, image rotation,
scale conversion, etc.) cannot be controlled, a visual system
must identify the image independent from its location, and
the transformations should not affect the performance of the
system. Therefore, the images that pass into each other under
some specific transformations must be classified as equivalent.
It should be noted that the human or mammalian visual
system to some extent is capable to extract the invariant
features of a signal. It took some effort to understand the
functions necessary for visual form perception. Based on the
knowledge about the receptive field (RF) reactions and about
the visual system in [5], [14], [17], [53], [54] a theory was developed according to which the visual system performs spatialfrequency image filtering. To adapt this effect to general signal
processing we have to understand how this filtering works. Let
us consider in more detail the visual path from the retina to
the cerebral cortex of primates. Visual information enters the
retina and is transmitted to the brain through about a million
nerve fibers that are united in the optic nerve [4], [6]. Most
of the optic nerve fibers reach without interruption two cell
nuclei that are located deep in the brain. These nuclei are
called lateral geniculate nuclei (LGN). In turn, neurons of the
LGN send their axons directly to the primary visual cortex
[4], [56].
The RF of a retinal ganglion cell refers to the synaptic
network of photoreceptors, bipolar, horizontal, and amacrine
cells which come together to this one ganglion cell [6].
A concentric RF has the central zone where the receptors
are stimulated to give response and a peripheral inhibitory
ring (off-on), or conversely, an inhibitory central zone and a
peripheral ring that gives response (on-off). Concentric fields
are used to describe the image by points [6]. Mathematically,
the spatiotemporal RF is defined by an impulse response function (weight function) describing the firing-rate response
to a tiny spot which is on for a very short time [23]. Some
methods of modelling this weight functions were developed
with difference of arouse and inhibitory Gaussians [23], [9],
[10], [16], [18], [20], with Gabor elements [11], [12], [13] and
others [19], [20].
Retinal ganglion cells project sensory information to the
lateral geniculate neurons of the thalamus. LGN neurons
replicate the center-surround structure of their presynaptic
partners [7]. Yet, this does not mean that the thalamic fields
are direct copies of those in the retina. A single LGN neuron
might receive inputs from multiple ganglion cells, hence the
spatial information sent from retina is remixed [61]. One LGN
neuron is overlapped with the ON (OFF) sub-region of the RF
of retinal cells according to feedforward or feedback excitation
[55], [51]. Hence RFs of the LGN describe spatial patterns of
light and dark regions around an average illuminance level
in the visual field [6], [51], [52]. The neural networks of the
visual cortex do not present a contour picture of the incoming
image which exists on the retina [5]. For effective processing
of incoming signals it is therefore necessary to reduce the
information redundancy, which, based on known studies, can
be assumed to be realized in the LGN [50]. Let us look into
more details of this process.
\clearpage

\clearpage

## Krawtchouk

\clearpage

### Fourier Decomposition

\clearpage

### Coefficient of Assymetry

\clearpage

### Energy Functional

\clearpage

### Artifact Removal

\clearpage

# Speed Comparison

\clearpage


## Stepwise Speed Comparison

\clearpage


\clearpage


## Memory Consumption

\clearpage

## Error of Function

\clearpage

\clearpage

# References

\clearpage

